---
title: "Быстрые сортировки. Сортировка подсчетом"
format:
  html:
    math: true
    page-layout: full
---

# Оптимальные сортировки

Можно ли сделать сортировку быстрее, чем ${\cal{O}(n^2)}$? Конечно.

Если у нас определена только операция "меньше", то мы не можем обойтись без ${\cal{O}(n \log n)}$ операций. Докажем это.

Введем понятие дерева решений. Дерево решений -- это бинарное дерево, в котором каждый узел представляет собой сравнение двух элементов массива. В каждом узле дерева находится подмножество множества всех перестановок на n элементов.

- В корне дерева находится множество всех перестановок.

- Каждый узел дерева представляет собой сравнение двух элементов массива. Если $a_i < a_j$, то мы идем в левое поддерево, иначе -- в правое. В корне левого поддерева находятся все перестановки, в которых $a_i < a_j$, а в корне правого поддерева -- все перестановки, в которых $a_i > a_j$.

- Каждый лист дерева представляет собой одну из возможных перестановок

- Значит, в таком дереве будет $n!$ листьев, так как у нас есть n элементов и $n!$ возможных перестановок.

- Поскольку дерево бинарное, то высота дерева будет равна $\log_2(n!)$.

Оценим снизу высоту дерева:

$$
    h = \log_2(n!) = \log_2 (n^n + \bar{o}(n^{n - 1})) \ge \log_2(n^n) = n \log_2(n)
$$

Поскольку, высота дерева равна количеству сравнений, то мы получаем нижнюю оценку на сложность сортировки:

$$
    \Omega \left( n \log_2(n) \right)
$$

## Сортировка слиянием (merge sort)

Сортировка слиянием -- это алгоритм вида "разделяй и властвуй", который разбивает массив на две половины до тех пор, пока каждая половина не станет размером в один элемент. Затем он объединяет эти половины обратно вместе в отсортированном порядке.

Введем вспомогательную операцию слияния двух отсортированных массивов. Эта операция принимает два отсортированных массива и объединяет их в один отсортированный массив. Это легко можно сделать, если создать два указателя, которые будут указывать на начало каждого массива. Затем мы будем сравнивать элементы, на которые указывают указатели, и добавлять меньший элемент в результирующий массив. После этого мы будем двигать указатель на массив, из которого был взят элемент. Когда один из массивов будет полностью обработан, мы просто добавим оставшиеся элементы другого массива в результирующий массив.

### Алгоритм слияния (псевдокод)

```Python
function merge(arr1, arr2):
    merged = []
    i = 0
    j = 0
    пока i < len(arr1) И j < len(arr2):
        если arr1[i] < arr2[j]:
            merged.append(arr1[i])
            i += 1
        иначе:
            merged.append(arr2[j])
            j += 1
    добавляем оставшиеся элементы из arr1 и arr2 в merged, если они есть
    возвращаем merged
```

Далее будем работать по следующей схеме:

1. Мы разбиваем массив на две половины.

2. Мы рекурсивно сортируем каждую половину.

3. Мы объединяем отсортированные половины обратно вместе с помощью операции слияния.

![image.png](/resources/images/merge_sort_downward.png)

![image-1.png](/resources/images/merge_sort_upward.png)

### Алгоритм сортировки слиянием (псевдокод)

```Python
function merge_sort(arr):
    если длина arr <= 1:
        возвращаем arr
    mid = длина arr // 2
    левая_часть = merge_sort(arr[:mid])
    правая_часть = merge_sort(arr[mid:])
    возвращаем merge(левая_часть, правая_часть)
```

Заметим, что сложность операции слияния составляет ${\cal{O}(n)}$, так как мы проходим по всем элементам обоих массивов. Разбивать массив на две половины можно не более $\log_2(n)$ раз.

Сложность такого алгоритма составляет:

$$
    {\cal{O}(n \log n)}
$$

## Быстрая сортировка (quick sort)

Быстрая сортировка -- это алгоритм вида "разделяй и властвуй", который разбивает массив на две части на основе опорного элемента (pivot по-английски),
где в левой половине хранятся элементы, меньше или равные опорному, а в правой -- большие опорного. Операция такого разделения называется partition. Затем алгоритм быстрой сортировки рекурсивно сортирует каждую из частей.

### Алгоритм partition (псевдокод)

Ниже приведен пример для Hoare partition.

```Python
функция partition(arr, l, r):
    v = arr[(l + r) // 2]
    i = l
    j = r
    пока i ≤ j:
        пока arr[i] < v:
            i = i + 1
        пока arr[j] > v:
            j = j - 1
        если i ≥ j:
            break
        поменять местами arr[i] и arr[j]
        i = i + 1
        j = j - 1
    вернуть j
```

Этот алгоритм работает следующим образом:

1. Мы выбираем опорный элемент

2. Идем с начала массва до тех пор, пока не найдем элемент, который больше опорного

3. Идем с конца массива до тех пор, пока не найдем элемент, который меньше опорного

4. Найденный элементы стоят не на своих местах, поэтому мы меняем их местами

5. Повторяем шаги 2-4 до тех пор, пока не дойдем до середины массива

После выполнения операции partition массив будет разбит на две части: элементы меньше или равные опорному и элементы больше опорного. Затем мы рекурсивно сортируем каждую из частей.

### Алгоритм быстрой сортировки (псевдокод)

```Python
function quick_sort(a, l, r):
    если l < r:
        q = partition(a, l, r)
        quick_sort(a, l, q)
        quick_sort(a, q + 1, r)
```

![image-3.png](/resources/images/quicksort_illustration.png)

Сложность такого алгоритма в среднем составляет:

$$
    {\cal{O}(n \log n)}
$$

Важно отметить, что быстрая сортировка работает быстрее, чем сортировка слиянием, так как она использует меньше памяти. Это связано с тем, что быстрая сортировка работает на месте (in-place), то есть не требует дополнительной памяти для хранения промежуточных массивов.

Также можно понимать, что в худшем случае сложность быстрой сортировки составляет ${\cal{O}(n^2)}$, например, когда разбиение массива происходит неудачно и массив разбивается на две части, одна из которых содержит $1$ элемент, а другая -- $n-1$ элементов. В этом случае быстрая сортировка будет работать так же, как сортировка выбором.

Интересно, что если способ выбора опорного элемента известен заранее, то всегда можно подобрать такой вход, что
сложность сортировки будет квадратичной. Например, если мы всегда выбираем первый элемент массива в качестве опорного, то массив, отсортированный по убыванию, будет работать за ${\cal{O}(n^2)}$.
В реальных задачах обычно используют случайный выбор опорного элемента, что позволяет избежать худшего случая.


# Сортировка подсчетом

Можно ли сделать сортировку быстрее, чем ${\cal{O}(n \log n)}$? Можно! Но для этого потребуется иметь больше инструментов, чем единственный оператор "меньше".

Все предыдущие алгоритмы работали с массивами, в которых лежат могут лежать абсолютно любые объекты, которые можно сравнивать: числа, строки, пары, другие массивы — почти все что угодно.

В особом случае, когда элементы могут принадлежать только какому-то небольшому множеству, можно использовать другой алгоритм — *сортировку подсчетом* (англ. *counting sort*).

Пусть, например, нам гарантируется, что все числа натуральные и лежат в промежутке от $1$ до $100$. Тогда есть такой простой алгоритм:

- Создадим массив размера $100$, в котором будем хранить на $k$-ом месте, сколько раз число $k$ встретилось в этом массиве.
- Пройдемся по всем числам исходного массива и увеличим соответствующее значение массива на $1$.
- После того, как мы посчитали, сколько раз каждое число встретилось, можно просто пройтись по этому массиву и вывести $1$ столько раз, сколько встретилась $1$, вывести $2$ столько раз, сколько встретилась $2$, и так далее.

Время работы такого алгоритма составляет $O(m + n)$, где $m$ — число возможных значений, $n$ — число элементов в массиве. Если количество возможных различных элементов в множестве относительно невелико, то сортировка подсчетом является одним из самых оптимальных решений.